# -*- coding: utf-8 -*-
"""BATADALRLCNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dbjxO7j9ObCefcSFPXeIkKs48FHEdQFM
"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 1.x

import pandas as pd

import numpy as np

fD = pd.read_csv("/content/drive/My Drive/newDatasets/BATADAL_dataset04.csv" , header=None)

#fD = pd.read_csv("/content/drive/My Drive/newDatasets/BATADAL_dataset02 (1).csv" , header=None)

test = pd.read_csv("/content/drive/My Drive/newDatasets/BATADAL_test_dataset.csv" , header=None)

test = test.drop(columns=0)
test = test.drop([0], axis=0)

test

Data = fD.drop(columns=0)

Data = Data.drop([0], axis=0)

Data

nData = Data.values

nData.shape

testData = test.values

xData = nData[:,:43]
yData = nData[:,43]

yData

xData[0]

nData[0]

xData.shape

testData.shape

xData=np.pad(xData,  ((0,0),(0,6)), 'constant', constant_values=0)

testData=np.pad(testData,  ((0,0),(0,6)), 'constant', constant_values=0)

test[:]

xData.shape

xData = xData.reshape(-1,7,7,1)

testData = testData.reshape(-1,7,7,1)

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(xData, yData, test_size=0.1, random_state=42)
print(X_train, y_train)

test = test.reshape(-1,7,7,1)

import matplotlib
import matplotlib.pyplot as plt

plt.imshow(xData[18][:,:,0].astype(float))

import keras
from keras.datasets import mnist
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D
import numpy as np
#from keras.optimizers import RMSprop, sgd
from keras.callbacks import LearningRateScheduler, ModelCheckpoint
from keras import optimizers
from keras.optimizers import RMSprop

import math



yData

from keras.models import Sequential
from keras.layers import Dense, Conv2D, Flatten
#create model
model = Sequential()
#add model layers
model.add(Conv2D(128, kernel_size=3, activation='relu', input_shape=(7,7,1)))
model.add(Dropout(0.2))
model.add(Conv2D(64, kernel_size=3, activation='relu'))
model.add(Flatten())
model.add(Dense(1, activation='sigmoid'))

#sgd = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)
#compile model using accuracy to measure model performance
#model.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['accuracy'])

#train the model
#model.fit(newXtrain, y_train, epochs=900)
def exp_decay(epoch):
    initial_lrate = 0.001
    k = 0.75
    t = 1024//(10000 * 32)  # every epoch we do n_obs/batch_size iteration
    lrate = initial_lrate * math.exp(-k*t)
    return lrate
sgd = optimizers.SGD(lr=0.0001)

lrate = LearningRateScheduler(exp_decay)
model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])

history = model.fit(xData, yData, 
                    epochs=100, 
                    batch_size=32, 
                     verbose=2,
                    callbacks=[lrate])

xData.shape

w = 0
xones = np.empty((219,7, 7, 1))
yones = np.ones(219)
for i in range (0, yData.shape[0]):
  if(yData[i] == "1"):
    xones[w] = xData[i]
    w = w +1

yData[1731:1731+200]

adam = optimizers.adam(lr=0.000000001)

model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])

history = model.fit(X_test.astype(float), y_test.astype(float), 
                    epochs=400, 
                    batch_size=32, 
                     verbose=2,
                    callbacks=[lrate],validation_split=0.3)

model.evaluate(X_test,y_test)

pred = model.predict_classes(X_test)

pred.shape

y_test = y_test.astype(float)

count = 0
for i in range(0,pred.shape[0]):
  print( pred[i][0], " ", y_test[i] )
  if pred[i][0].astype(float) == y_test[i].astype(float):
    count = count + 1
print("Acc: ", count/1379)

norm = pd.read_csv("/content/drive/My Drive/newDatasets/BATADAL_dataset03.csv" , header=None)

norm = norm.drop(columns=0);
norm = norm.drop([0],axis=0)

xnorm = norm.values[:,:43]
ynorm = norm.values[:,43]

ynorm[1500:2000]

xnorm=np.pad(xnorm,  ((0,0),(0,6)), 'constant', constant_values=0)

xnorm = xnorm.reshape(-1,7,7,1);

history = model.fit(xnorm, ynorm, 
                    epochs=60, 
                    batch_size=32, 
                     verbose=2,
                    callbacks=[lrate],validation_split=0.3)

"""# ROC"""

from sklearn.datasets import make_classification
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_curve
from sklearn.metrics import roc_auc_score
from matplotlib import pyplot

ns_probs = [0 for _ in range(len(y_test))]

lr_probs = model.predict_proba(X_test)
# keep probabilities for the positive outcome only
lr_probs = lr_probs[:, 0]
# calculate scores
ns_auc = roc_auc_score(y_test, ns_probs)
lr_auc = roc_auc_score(y_test, lr_probs)
# summarize scores
print('No Skill: ROC AUC=%.3f' % (ns_auc))
print('Logistic: ROC AUC=%.3f' % (lr_auc))
# calculate roc curves
ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)
lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)
# plot the roc curve for the model
pyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')
pyplot.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')
# axis labels
pyplot.xlabel('False Positive Rate')
pyplot.ylabel('True Positive Rate')
# show the legend
pyplot.legend()
# show the plot
pyplot.show()

lr_probs

xones[50] = xData[50]
yones[50] = yData[50]

"""New Stuff
# New Section
"""

ypred = model.predict(X_test)

ypred = np.around(ypred)

yData

xData.shape

yData[2300:2400]

ss = np.rint(ypred)
ss
ypred = ss

ypred[0:44]

xones[:20] = xData[:20]
yones[0:20]= yData[:20]

from sklearn.metrics import classification_report, confusion_matrix
a = y_test.astype(float)
b = ypred
print('Confusion Matrix')
print(confusion_matrix(a, b))
print('Classification Report')
target_names = ['Good','Malware']
print(classification_report(a, b, target_names=target_names))

xData.shape

yones[218]= 0

y_train = y_train.astype(np.float)

"""# Roc"""

from sklearn.datasets import make_classification
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_curve
from sklearn.metrics import roc_auc_score
from matplotlib import pyplot

# Get predicted probabilities
    y_score1 = model.predict_proba(X_test)[:,0]

    # Plot Receiving Operating Characteristic Curve
    # Create true and false positive rates
    false_positive_rate1, true_positive_rate1, threshold1 = roc_curve(y_test.astype(float), y_score1)
    print('roc_auc_score for DecisionTree: ', roc_auc_score(y_test.astype(float), y_score1))
    #print("nas" , true_positive_rate1,false_positive_rate1)
    # Plot ROC curves
    plt.title('Receiver Operating Characteristic')
    plt.plot(false_positive_rate1, true_positive_rate1)
  
    plt.ylabel('True Positive Rate')
    plt.xlabel('False Positive Rate')
    plt.savefig("BatadalROCSAVE.png")

counter = 0 
ypredtest = np.around(model.predict(testData))
for x in ypredtest:
  if x > 0:
    print(counter)
  counter = counter + 1

test[30]

testData.shape

from sklearn.metrics import confusion_matrix

y_true = ['Cat', 'Dog', 'Rabbit', 'Cat', 'Cat', 'Rabbit']
y_pred = ['Dog', 'Dog', 'Rabbit', 'Dog', 'Dog', 'Rabbit']

classes=['Normal', 'Attack']

#confusion_matrix(y_true, y_pred, labels=['Cat', 'Dog', 'Rabbit'])

def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):
    """
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    """
    import itertools
    normalize=True
    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    print(cm)

    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    fmt = '.2f' if normalize else 'd'
    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, format(cm[i, j], fmt),
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

    plt.ylabel('True label')
    plt.xlabel('Predicted label')
    plt.tight_layout()
    plt.savefig("cmBatadal.png")

cnf_matrix = confusion_matrix(y_test.astype(float), ypred,labels=[0,1])
np.set_printoptions(precision=2)

# Plot non-normalized confusion matrix
plt.figure()
plot_confusion_matrix(cnf_matrix, classes,
                      title='Normalized Confusion Matrix')